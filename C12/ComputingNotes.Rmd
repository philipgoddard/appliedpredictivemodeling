---
title: "C12 Computing Notes"
output: html_document
---
# Preprocessing

* see script in APM package. Note that small error using lubridate::day() - with version 1.3.3 day() defaults to mday(), where authors intended the result from yday()

```{r, message=FALSE, echo=FALSE, cache=TRUE}
################################################################################
### R code from Applied Predictive Modeling (2013) by Kuhn and Johnson.
### Copyright 2013 Kuhn and Johnson
### Web Page: http://www.appliedpredictivemodeling.com
### Contact: Max Kuhn (mxkuhn@gmail.com) 
###
### R code to process the Kaggle grant application data.
###
### Required packages: plyr, caret, lubridate
###                   
###
### Data used: The file unimelb_training.csv
###
### Notes: 
### 1) This code is provided without warranty.
###
### 2) This code should help the user reproduce the results in the
### text. There will be differences between this code and what is is
### the computing section. For example, the computing sections show
### how the source functions work (e.g. randomForest() or plsr()),
### which were not directly used when creating the book. Also, there may be 
### syntax differences that occur over time as packages evolve. These files 
### will reflect those changes.
###
### 3) In some cases, the calculations in the book were run in 
### parallel. The sub-processes may reset the random number seed.
### Your results may slightly vary.
###
################################################################################

## The plyr, caret and libridate packages are used in this script. The
## code can also be run using multiple cores using the ddply()
## function. See ?ddply to get more information.
##
## The user will need the unimelb_training.csv file from the
## competition.
##
## These computations will take a fair amount of time and may consume
## a non-trivial amount of memory in the process.
##

## Load required libraries
library("plyr")
library("caret")
library("lubridate")

## How many cores on the machine should be used for the data
## processing. Making cores > 1 will speed things up (depending on your
## machine) but will consume more memory.
cores <- 3

if(cores > 1) {
    library(doMC)
    registerDoMC(cores)
  }

## Read in the data in it's raw form. Some of the column headings do
## not convert to proper R variable names, so many will contain dots,
## such as "Dept.No" instead of "Dept No"
raw <- read.csv("../grant_data/unimelb_training.csv")

## In many cases, missing values in categorical data will be converted
## to a value of "Unk"
raw$Sponsor.Code <- as.character(raw$Sponsor.Code)
raw$Sponsor.Code[raw$Sponsor.Code == ""] <- "Unk"
raw$Sponsor.Code <- factor(paste("Sponsor", raw$Sponsor.Code, sep = ""))

raw$Grant.Category.Code <- as.character(raw$Grant.Category.Code)
raw$Grant.Category.Code[raw$Grant.Category.Code == ""] <- "Unk"
raw$Grant.Category.Code <- factor(paste("GrantCat", raw$Grant.Category.Code, sep = ""))

raw$Contract.Value.Band...see.note.A <- as.character(raw$Contract.Value.Band...see.note.A)
raw$Contract.Value.Band...see.note.A[raw$Contract.Value.Band...see.note.A == ""] <- "Unk"
raw$Contract.Value.Band...see.note.A <- factor(paste("ContractValueBand", raw$Contract.Value.Band...see.note.A, sep = ""))

## Change missing Role.1 information to Unk
raw$Role.1 <- as.character(raw$Role.1)
raw$Role.1[raw$Role.1 == ""] <- "Unk"

## Get the unique values of the birth years and department
## codes. These will be used later to make factor variables
bYears <- unique(do.call("c", raw[,grep("Year.of.Birth", names(raw), fixed = TRUE)]))
bYears <- bYears[!is.na(bYears)]

dpmt <- unique(do.call("c", raw[,grep("Dept.No", names(raw), fixed = TRUE)]))
dpmt <- sort(dpmt[!is.na(dpmt)])

## At this point, the data for investigators is in different
## columns. We'll take this "horizontal" format and convert it to a
## "vertical" format where the data are stacked. This will make some
## of the data processing easier.

## Split up the data by role number (1-15) and add any missing columns
## (roles 1-5 have more columns than the others)
tmp <- vector(mode = "list", length = 15)
for(i in 1:15) {
    tmpData <- raw[, c("Grant.Application.ID", grep(paste("\\.", i, "$", sep = ""), names(raw), value = TRUE))]
    names(tmpData) <- gsub(paste("\\.", i, "$", sep = ""), "", names(tmpData))
    if(i == 1) nms <- names(tmpData)
    if(all(names(tmpData) != "RFCD.Code")) tmpData$RFCD.Code <- NA
    if(all(names(tmpData) != "RFCD.Percentage")) tmpData$RFCD.Percentage <- NA
    if(all(names(tmpData) != "SEO.Code")) tmpData$SEO.Code <- NA
    if(all(names(tmpData) != "SEO.Percentage")) tmpData$SEO.Percentage <- NA

    tmp[[i]] <- tmpData[,nms]
    rm(tmpData)
  }
## Stack them up and remove any rows without role information
vertical <- do.call("rbind", tmp)
vertical <- subset(vertical, Role != "")

## Reformat some of the variables to make complete factors, correctly
## encode missing data or to make the factor levels more descriptive.

vertical$Role <- factor(as.character(vertical$Role))

vertical$Year.of.Birth <- factor(paste(vertical$Year.of.Birth), levels = paste(sort(bYears)))
vertical$Country.of.Birth <- gsub(" ", "", as.character(vertical$Country.of.Birth))
vertical$Country.of.Birth[vertical$Country.of.Birth == ""] <- NA
vertical$Country.of.Birth <- factor(vertical$Country.of.Birth)

vertical$Home.Language <- gsub("Other", "OtherLang", as.character(vertical$Home.Language))
vertical$Home.Language[vertical$Home.Language == ""] <- NA
vertical$Home.Language <- factor(vertical$Home.Language)

vertical$Dept.No. <- paste("Dept", vertical$Dept.No., sep = "")
vertical$Dept.No.[vertical$Dept.No. == "DeptNA"] <- NA
vertical$Dept.No. <- factor(vertical$Dept.No.)

vertical$Faculty.No. <- paste("Faculty", vertical$Faculty.No., sep = "")
vertical$Faculty.No.[vertical$Faculty.No. == "FacultyNA"] <- NA
vertical$Faculty.No. <- factor(vertical$Faculty.No.)

vertical$RFCD.Code <- paste("RFCD", vertical$RFCD.Code, sep = "")
vertical$RFCD.Percentage[vertical$RFCD.Code == "RFCDNA"] <- NA
vertical$RFCD.Code[vertical$RFCD.Code == "RFCDNA"] <- NA
vertical$RFCD.Percentage[vertical$RFCD.Code == "RFCD0"] <- NA
vertical$RFCD.Code[vertical$RFCD.Code == "RFCD0"] <- NA
vertical$RFCD.Percentage[vertical$RFCD.Code == "RFCD999999"] <- NA
vertical$RFCD.Code[vertical$RFCD.Code == "RFCD999999"] <- NA
vertical$RFCD.Code <- factor(vertical$RFCD.Code)

vertical$SEO.Code <- paste("SEO", vertical$SEO.Code, sep = "")
vertical$SEO.Percentage[vertical$SEO.Code == "SEONA"] <- NA
vertical$SEO.Code[vertical$SEO.Code == "SEONA"] <- NA
vertical$SEO.Percentage[vertical$SEO.Code == "SEO0"] <- NA
vertical$SEO.Code[vertical$SEO.Code  == "SEO0"] <- NA
vertical$SEO.Percentage[vertical$SEO.Code == "SEO999999"] <- NA
vertical$SEO.Code[vertical$SEO.Code== "SEO999999"] <- NA
vertical$SEO.Code <- factor(vertical$SEO.Code)

vertical$No..of.Years.in.Uni.at.Time.of.Grant <- as.character(vertical$No..of.Years.in.Uni.at.Time.of.Grant)
vertical$No..of.Years.in.Uni.at.Time.of.Grant[vertical$No..of.Years.in.Uni.at.Time.of.Grant == ""] <- "DurationUnk"
vertical$No..of.Years.in.Uni.at.Time.of.Grant[vertical$No..of.Years.in.Uni.at.Time.of.Grant == ">=0 to 5"] <- "Duration0to5"
vertical$No..of.Years.in.Uni.at.Time.of.Grant[vertical$No..of.Years.in.Uni.at.Time.of.Grant == ">5 to 10"] <- "Duration5to10"
vertical$No..of.Years.in.Uni.at.Time.of.Grant[vertical$No..of.Years.in.Uni.at.Time.of.Grant == ">10 to 15"] <- "Duration10to15"
vertical$No..of.Years.in.Uni.at.Time.of.Grant[vertical$No..of.Years.in.Uni.at.Time.of.Grant == "more than 15"] <- "DurationGT15"
vertical$No..of.Years.in.Uni.at.Time.of.Grant[vertical$No..of.Years.in.Uni.at.Time.of.Grant == "Less than 0"] <- "DurationLT0"
vertical$No..of.Years.in.Uni.at.Time.of.Grant <- factor(vertical$No..of.Years.in.Uni.at.Time.of.Grant)


######################################################################
## A function to shorten the role titles

shortNames <- function(x, pre = ""){
    x <- gsub("EXT_CHIEF_INVESTIGATOR",  "ECI", x)
    x <- gsub("STUD_CHIEF_INVESTIGATOR", "SCI", x)
    x <- gsub("CHIEF_INVESTIGATOR",      "CI", x)
    x <- gsub("DELEGATED_RESEARCHER",    "DR", x)
    x <- gsub("EXTERNAL_ADVISOR",        "EA", x)
    x <- gsub("HONVISIT",                "HV", x)
    x <- gsub("PRINCIPAL_SUPERVISOR",    "PS", x)
    x <- gsub("STUDRES",                 "SR", x)
    x <- gsub("Unk",                     "UNK", x)
    other <- x[x != "Grant.Application.ID"]
    c("Grant.Application.ID", paste(pre, other, sep = ""))
  }

## A function to find and remove zero-variance ("ZV") predictors
noZV <- function(x) {
    keepers <- unlist(lapply(x, function(x) length(unique(x)) > 1))
    x[,keepers,drop = FALSE]
  }


######################################################################
## Calculate the total number of people identified on the grant

people <- ddply(vertical, .(Grant.Application.ID), function(x) c(numPeople = nrow(x)))

######################################################################
## Calculate the number of people per role

investCount <- ddply(vertical, .(Grant.Application.ID),
                     function(x) as.data.frame(t(as.matrix(table(x$Role)))),
                     .parallel = cores > 1)

## Clean up the names
names(investCount) <- shortNames(names(investCount), "Num")

######################################################################
## For each role, calculate the frequency of people in each age group

investDOB <- ddply(vertical, .(Grant.Application.ID),
                   function(x) {
                     tabDF <- as.data.frame(table(x$Role, x$Year.of.Birth))
                     out <- data.frame(t(tabDF$Freq))
                     names(out) <- paste(tabDF$Var1, tabDF$Var2, sep = ".")
                     out
                   },
                   .parallel = cores > 1)
names(investDOB) <- shortNames(names(investDOB))
investDOB <- noZV(investDOB)

######################################################################
## For each role, calculate the frequency of people from each country

investCountry <- ddply(vertical, .(Grant.Application.ID),
                       function(x) {
                         tabDF <- as.data.frame(table(x$Role, x$Country.of.Birth))
                         out <- data.frame(t(tabDF$Freq))
                         names(out) <- paste(tabDF$Var1, tabDF$Var2, sep = ".")
                         out
                       },
                       .parallel = cores > 1)
names(investCountry) <- shortNames(names(investCountry))
investCountry <- noZV(investCountry)

######################################################################
## For each role, calculate the frequency of people for each language

investLang <- ddply(vertical, .(Grant.Application.ID),
                    function(x) {
                      tabDF <- as.data.frame(table(x$Role, x$Home.Language))
                      out <- data.frame(t(tabDF$Freq))
                      names(out) <- paste(tabDF$Var1, tabDF$Var2, sep = ".")
                      out
                    },
                    .parallel = cores > 1)
names(investLang) <- shortNames(names(investLang))
investLang <- noZV(investLang)

######################################################################
## For each role, determine who as a Ph.D.

investPhD <- ddply(vertical, .(Grant.Application.ID),
                   function(x) {
                     tabDF <- as.data.frame(table(x$Role, x$With.PHD))
                     out <- data.frame(t(tabDF$Freq))
                     names(out) <- paste(tabDF$Var1, tabDF$Var2, sep = ".")
                     out
                   },
                   .parallel = cores > 1)
investPhD <- investPhD[,-grep("\\.$", names(investPhD))]
names(investPhD) <- shortNames(names(investPhD))
names(investPhD) <- gsub("Yes ", "PhD", names(investPhD))
investPhD <- noZV(investPhD)

######################################################################
## For each role, calculate the number of successful and unsuccessful
## grants

investGrants <- ddply(vertical, .(Grant.Application.ID, Role),
                      function(x) {
                        data.frame(Success = sum(x$Number.of.Successful.Grant, na.rm = TRUE),
                                   Unsuccess = sum(x$Number.of.Unsuccessful.Grant, na.rm = TRUE))

                      },
                      .parallel = cores > 1)
investGrants <- reshape(investGrants, direction = "wide", idvar = "Grant.Application.ID", timevar = "Role")
investGrants[is.na(investGrants)] <- 0

names(investGrants) <- shortNames(names(investGrants))
investGrants <- noZV(investGrants)

######################################################################
## Create variables for each role/department combination

investDept <- ddply(vertical, .(Grant.Application.ID),
                    function(x) {
                      tabDF <- as.data.frame(table(x$Role, x$Dept.No.))
                      out <- data.frame(t(tabDF$Freq))
                      names(out) <- paste(tabDF$Var1, tabDF$Var2, sep = ".")
                      out
                    },
                    .parallel = cores > 1)
names(investDept) <- shortNames(names(investDept))
investDept <- noZV(investDept)

######################################################################
## Create variables for each role/faculty #


investFaculty <- ddply(vertical, .(Grant.Application.ID),
                       function(x) {
                         tabDF <- as.data.frame(table(x$Role, x$Faculty.No.))
                         out <- data.frame(t(tabDF$Freq))
                         names(out) <- paste(tabDF$Var1, tabDF$Var2, sep = ".")
                         out
                       },
                       .parallel = cores > 1)
names(investFaculty) <- shortNames(names(investFaculty))
investFaculty <- noZV(investFaculty)

######################################################################
## Create dummy variables for each tenure length

investDuration <- ddply(vertical, .(Grant.Application.ID),
                     function(x) as.data.frame(t(as.matrix(table(x$No..of.Years.in.Uni.at.Time.of.Grant)))),
                     .parallel = cores > 1)
investDuration[is.na(investDuration)] <- 0


######################################################################
## Create variables for the number of publications per journal
## type. Note that we also compute the total number, which should be
## removed for models that cannot deal with such a linear dependency

totalPub <- ddply(vertical, .(Grant.Application.ID),
                   function(x) {
                     data.frame(AstarTotal = sum(x$A., na.rm = TRUE),
                                ATotal = sum(x$A, na.rm = TRUE),
                                BTotal = sum(x$B, na.rm = TRUE),
                                CTotal = sum(x$C, na.rm = TRUE),
                                allPub = sum(c(x$A., x$A, x$B, x$C), na.rm = TRUE))

                   },
                   .parallel = cores > 1)

######################################################################
## Create variables for the number of publications per journal
## type per role.

investPub <- ddply(vertical, .(Grant.Application.ID, Role),
                   function(x) {
                     data.frame(Astar = sum(x$A., na.rm = TRUE),
                                A = sum(x$A, na.rm = TRUE),
                                B = sum(x$B, na.rm = TRUE),
                                C = sum(x$C, na.rm = TRUE))

                   },
                   .parallel = cores > 1)
investPub <- reshape(investPub, direction = "wide", idvar = "Grant.Application.ID", timevar = "Role")
investPub[is.na(investPub)] <- 0

names(investPub) <- shortNames(names(investPub))
investPub <- noZV(investPub)

######################################################################
## Create variables for each RFCD code

RFCDcount <- ddply(vertical, .(Grant.Application.ID),
                     function(x) as.data.frame(t(as.matrix(table(x$RFCD.Code)))),
                     .parallel = cores > 1)
RFCDcount <- noZV(RFCDcount)

######################################################################
## Create variables for each SEO code

SEOcount <- ddply(vertical, .(Grant.Application.ID),
                     function(x) as.data.frame(t(as.matrix(table(x$SEO.Code)))),
                     .parallel = cores > 1)
SEOcount <- noZV(SEOcount)

######################################################################
### Make dummy vars out of grant-specific data

grantData <- raw[, c("Sponsor.Code", "Contract.Value.Band...see.note.A", "Grant.Category.Code")]

## Make a lubridate object for the time, then derive the day, week and month info
startTime <- dmy(raw$Start.date)

grantData$Month <- factor(as.character(month(startTime, label = TRUE)))
grantData$Weekday <- factor(as.character(wday(startTime, label = TRUE)))

# THIS IS AN ERROR, PG FIXED day() to yday() - day() defaults to mday()
grantData$Day <- yday(startTime)
grantYear <- year(startTime)

######################################################################
### Use the dummyVars function to create binary variables for
### grant-specific variables

dummies <- dummyVars(~., data = grantData, levelsOnly = TRUE)
grantData <- as.data.frame(predict(dummies, grantData))
names(grantData) <- gsub(" ", "", names(grantData))

grantData$Grant.Application.ID <- raw$Grant.Application.ID
grantData$Class <- factor(ifelse(raw$Grant.Status, "successful", "unsuccessful"))
grantData$Grant.Application.ID <- raw$Grant.Application.ID

grantData$is2008 <- year(startTime) == 2008
grantData <- noZV(grantData)

######################################################################
### Merge all the predictors together, remove zero variance columns
### and merge in the outcome data
summarized <- merge(investCount, investDOB)
summarized <- merge(summarized, investCountry)
summarized <- merge(summarized, investLang)
summarized <- merge(summarized, investPhD)
summarized <- merge(summarized, investGrants)
summarized <- merge(summarized, investDept)
summarized <- merge(summarized, investFaculty)
summarized <- merge(summarized, investDuration)
summarized <- merge(summarized, investPub)
summarized <- merge(summarized, totalPub)
summarized <- merge(summarized, people)
summarized <- merge(summarized, RFCDcount)
summarized <- merge(summarized, SEOcount)

summarized <- merge(summarized, grantData)
## Remove the ID column
summarized$Grant.Application.ID <- NULL
# print(str(summarized))

######################################################################
### We'll split all of the pre-2008 data into the training set and a
### portion of the 2008 data too

training <- subset(summarized, !is2008)
pre2008 <- 1:nrow(training)
year2008 <- subset(summarized, is2008)

## Now randomly select some 2008 data for model training and add it
## back into the existing training data
set.seed(568)
inTrain <- createDataPartition(year2008$Class, p = 3/4)[[1]]
training2 <- year2008[ inTrain,]
testing   <- year2008[-inTrain,]
training <- rbind(training, training2)

training$is2008 <- testing$is2008 <- NULL

training <- noZV(training)
testing <- testing[, names(training)]

######################################################################
### Create two character vectors for different predictor sets. One
### will have all the predictors (called 'fullSet').
##
### Another has some of the sparse predictors removed for models that
### require such filtering. This will be called 'reducedSet'
### (predictors without sparse or Near Zero Variance predictors). This
### set will also have predictors removed that are almost completely
### correlated with other predictors

fullSet <- names(training)[names(training) != "Class"]

###################################################################
### In the classification tree chapter, there is a different set
### of predictors that use factor encodings of some of the 
### predictors

factorPredictors <- names(training)[names(training) != "Class"]
factorPredictors <- factorPredictors[!grepl("Sponsor[0-9]", factorPredictors)]
factorPredictors <- factorPredictors[!grepl("SponsorUnk", factorPredictors)]
factorPredictors <- factorPredictors[!grepl("ContractValueBand[A-Z]", factorPredictors)]
factorPredictors <- factorPredictors[!grepl("GrantCat", factorPredictors)]
factorPredictors <- factorPredictors[!(factorPredictors %in% levels(training$Month))]
factorPredictors <- factorPredictors[!(factorPredictors %in% levels(training$Weekday))]

factorForm <- paste("Class ~ ", paste(factorPredictors, collapse = "+"))
factorForm <- as.formula(factorForm)

### Some are extremely correlated, so remove
predCorr <- cor(training[,fullSet])
highCorr <- findCorrelation(predCorr, .99)
fullSet <- fullSet[-highCorr]

isNZV <- nearZeroVar(training[,fullSet], saveMetrics = TRUE, freqCut = floor(nrow(training)/5))
fullSet <-  rownames(subset(isNZV, !nzv))
# str(fullSet)

reducedSet <- rownames(subset(isNZV, !nzv & freqRatio < floor(nrow(training)/50)))

### Perfectly collinear predictors (due to their construction) March
### and Sunday were selected because they have the lowest frequency of
### all months and days
reducedSet <- reducedSet[(reducedSet != "allPub") &
                         (reducedSet != "numPeople") &
                         (reducedSet != "Mar") &
                         (reducedSet != "Sun")
                         ]

### all months and days
reducedSet <- reducedSet[(reducedSet != "allPub") &
                         (reducedSet != "numPeople") &
                         (reducedSet != "Mar") &
                         (reducedSet != "Sun")
                         ]
# str(reducedSet)

# sessionInfo()
```

```{r}
names(fullSet)
```

# Modelling

```{r, echo=FALSE, message=FALSE}
library("caret")
library("AppliedPredictiveModeling")
library("glmnet")
library("MASS")
library("pamr")
library("pls")
library("pROC")
library("rms")
library("sparseLDA")
library("subselect")
library("RColorBrewer")
```

* Lets start by having a look around. My challenge is to reproduce the above munging (use dplyr as plyr sooooo slow!)- looks like good practice

```{r}
# two character vectors for specifying either group:
length(fullSet)
head(fullSet)
```

```{r}
length(reducedSet)
head(reducedSet)
```

### Diagnosing extereme colliniearity

* The trim.matrix() function in subselect takes a square symmetric matrix (in our case the covariance matrix) an eliminates linear combinations

```{r, cache=TRUE}
reducedCovMat <- cov(training[, reducedSet])
trimmingResults <- trim.matrix(reducedCovMat)
names(trimmingResults)
trimmingResults$names.discarded
```

* however, when display the same function to the full set, several predictors are identified:

```{r, cache=TRUE}
fullCovMat <- cov(training[, fullSet])
fullSetResults <- trim.matrix(fullCovMat)
fullSetResults$names.discarded
```

* caret::findLinearCombos() follows a similar methodology but does not require a square matrix

## Training Models

* When training models, want train to select based on AUC of ROC curve. By default, overall accuracy and Kappa are used to evaluate models. summaryFunction argument in trainControl() does this

* Need to change some defailts on caret's train function as we want class probabilities as well as predictions. classProbs argument in trainControl() does this

* A data splitting scheme was decided that build the model on pre 2008 data and then used the 2009 holdout data in the training set to tune the model. To do this, train() must know exactly which samples to use when estimating parameter. The index argument in trainControl identifies these samples. For any resampling method, a set of hildout samples can be exactly specified. So index identifies the rows that correspond to the pre-2008 data... in other words model built to pre 2008, tuned to 2008 

* Note that one the tuning parameters are chosen using 2008 performance estimates, the final model is fit with all grants in training set, including those from 2008

* Finally, want to save the preditcions of the 2008 grants based on the pre-2008 models (ie before the final model is refit with all of the training data)


```{r}
ctrl <- trainControl(method = "LGOGV",
                     summaryFunction = twoClassSummary,
                     classProbs = TRUE,
                     index = list(TrainSet = pre2008),
                     savePredictions = TRUE)
set.seed(476)
```

### Logistic Regression

* The glm function in base R is commonly used to fit logistic regression models


```{r}
levels(training$Class)

# simple example
modelFit <- glm(Class ~ Day,
                data = training[pre2008, ],
                # family relates to the distribution of data
                # is binomial for logistic regression
                family = binomial)

modelFit
```

* The glm function treats the second factor level as the event of interest. Since the slope is positive for day of year it indicates an increase in the rate of unsuccessful grants. To get the probability of a succesful grant, we subtract from one:


```{r}
successProb <- 1 - predict(modelFit,
                           # predict for several days
                           newdata = data.frame(Day = c(10, 150, 300, 350)),
                           # glm does not predict the class, but can produce
                           # probability of the event
                           type = "response")

successProb
```

* To add non linear terms, can augment formula:

```{r}
daySquaredModel <- glm(Class ~ Day + I(Day^2),
                       data = training[pre2008, ],
                       family = binomial)

daySquaredModel
```

* Annoyingly, the glm() function does not have a non-formula method, so creating models with a large number of predictors takes a little work. Alternative methods will be shown shortly.

* The function rms::lrm() is very similar to glm, and includes helper functions. for example, a restricted cubic spline is a tool for fitting flexible nonlinear functions of a predictor. For day of the year:

```{r}
rcsFit <- lrm(Class ~ rcs(Day),
              data = training[pre2008, ])
rcsFit
```

* By looking at p-values for first few terms, can decide if a non-linear relationship between class and day should be used. Can use rms::Predict() to quickly create a prediction profile accross one or more variabls:

```{r, fig.width=5, fig.height=5}
dayProfile <- Predict(rcsFit,
                      # Specify the range of the plot variable
                      Day = 0:365,
                      # Flip the prediction to get the model for 
                      # successful grants
                      fun = function(x) -x)
plot(dayProfile, ylab = "log odds")
```


* The plot shoes the log odds - fun argumnet has changed to p of success. It is apparaent that a quadratic term would benefit the model- it would approximate well the trends in the spline

* The train function can be applied for glm to efficiently train and validate models.

* Prior to fitting, add day squared term

```{r}
training$Day2 <- training$Day^2
testing$Day2 <- testing$Day^2
fullSet <- c(fullSet, "Day2")
reducedSet <- c(reducedSet, "Day2")
```

```{r, eval=FALSE}
set.seed(476)
lrFull <- train(training[, fullSet],
                y = training$Class,
                method = "glm",
                metric = "ROC",
                trControl = ctrl)

# get very poor perfomance, algorithm does not converge
# consider filtered below
```

* note at top of output reflect 8190 grants, but summary of sample size lists 6633. The latter reflects the single set of pre-2008 samples. The resampling results is actually the performance of the 2008- holdout set

```{r, cache=T}
# for reduced set
lrReduced <- train(training[, reducedSet],
                y = training$Class,
                method = "glm",
                metric = "ROC",
                trControl = ctrl)
lrReduced
```

* the removal of near zero variance precitors yeilds a fairly good fit. The predictions on the holdout sets are held in sub object pred

```{r, fig.width=5, fig.height=5}
# not the .parameter column. When train saves predictions, it does so for every tuning parameter. 
# This column labels which model generated the predictions. Here, no tuning params, hence 'none'
head(lrReduced$pred)

# and can make a confusion matrix
confusionMatrix(data = lrReduced$pred$pred,
                reference = lrReduced$pred$obs)

# ROC and AUC:

reducedRoc <- roc(response = lrReduced$pred$obs,
                  predictor = lrReduced$pred$successful,
                  # this function assumes that the second
                  # class is the event of interest, so we
                  # reverse the labels
                  levels = rev(levels(lrReduced$pred$obs)))

# use legacy axes so 1-spec vs sens
plot(reducedRoc, legacy.axes = TRUE)
auc(reducedRoc)
```

## Linear Discriminant Analysis

* The MASS::lda is a popular function for LDA models. UInput is either a formula or data frame or matrix of predictirs and a grouping variable a s a factor tha contains the class membership information

```{r}
# center and scale
grantPreProcess <- preProcess(training[pre2008, reducedSet])
grantPreProcess

scaledPre2008 <- predict(grantPreProcess,
                         newdata = training[pre2008, reducedSet])
scaled2008HoldOut <- predict(grantPreProcess,
                             newdata = training[-pre2008, reducedSet])

ldaModel <- lda(x = scaledPre2008,
                 grouping = training$Class[pre2008])
```

* As inly two calsses, only one discriminant vector can be obtained. The discriminant vector is held in ldaModel$scaling

```{r}
head(ldaModel$scaling)
```

* This information proveds an interpretation aboutpredictors, reloationships amongst predictoors, and if centering and scaling applied, relative importance values. For predictions:

```{r}
ldaHoldOutPred <- predict(ldaModel, scaled2008HoldOut)
```

* The predicted class, posterior probability and linear discriminat value are all ocntained in this object, thus enabling creating of a confusion matrix, the distribution of posterior probabilities and the distributin of linear discriminant values.

* As we are in a two class setting, there is no training over number of discriminant values (there is just 1). When there are more than two classes, optimal number of discriminant vectors can be caculated in usual way with train(). MASS::lda() has argument dimen in the predict() method. Can automate training with


```{r}
set.seed(476)
ldaFit1 <- train(x = training[, reducedSet],
                 y = training$Class,
                 method = "lda",
                 preProc = c("center", "scale"),
                 metric = "ROC",
                 trControl = ctrl)
ldaFit1

confusionMatrix(data = ldaFit1$pred$pred,
                reference = ldaFit1$pred$obs)

ldaTestClasses <- predict(ldaFit1,
                          newdata = testing[, reducedSet])
ldaTestProbs <- predict(ldaFit1,
                        newdata = testing[, reducedSet],
                        type = "prob")
```

* When the problem involves more than two classes we desire to optimise over the number of discriminant vectors, use train() with method = "lda2" and tuneLength set to the max number of dimenensions wished to evaluate.

## PLS Discriminant Analysis

* PLSDA can be performed using the plsr function within the pls package by using a categorical matrix which defines the response categories. The caret package conatins a function (plsda) that can create the appropriate dummy variable PLS model for the dat and then post-process the raw model predictions to return class probabilities. 

* Syntax siminalr to regression model pls, main difference is that a factor variable used for outcome.

```{r, cache=TRUE}
plsdaModel <- plsda(x = training[pre2008, reducedSet],
                    y = training[pre2008, "Class"],
                    # data should be on same scale
                    scale = TRUE,
                    # use bayes method for probs
                    probMethod = "Bayes",
                    # specifiy ncomponents
                    ncomp = 4)

# predict hold-out set
plsPred <- predict(plsdaModel,
                   newdata = training[-pre2008, reducedSet])
head(plsPred)
plsProbs <- predict(plsdaModel,
                    newdata = training[-pre2008, reducedSet],
                    type = "prob")
```

* As the plsdaModel object inherits from the same functions taht would have resulted from the object coming directly from the plsr function, we can use other functions like loadings() and scoreplot()

* The train function can be used with PLS in the classification setting. I guess we should keep probMethod as Bayes?? (could just check if predections are same)

```{r, cache=T}
set.seed(476)
plsFit2 <- train(x = training[, reducedSet],
                 y = training$Class,
                 method = "pls",
                 tuneGrid = expand.grid(ncomp = 1:10),
                 preProc = c("center", "scale"),
                 metric = "ROC",
                 trControl = ctrl,
                 probMethod = "Bayes")

plsFit2
```

* The basic predict() function evaluates the new samples, and with type="prob" argument returns class probabilities. Variable importance can be computed thus:

```{r}
plsImpGrant <- varImp(plsFit2, scale = FALSE)
plot(plsImpGrant, top = 20, scales = list(y = list(cex = 0.95)))
```

## Penalized Models

* The main package used for penalized methods is gmlnet. Very similar to enet. Main arguments correspond to the data: x is a matrix of predictors and y is a factor of classes (for logistic regression)

* The family argument must be "binomial" for two-class settings, and "multinomial" for three or more.

* The function automatically slescts a sequence of values for the amount of regularization, although user can select own values with lambda option. The amount of regularization is chosen by mixing param alpha. glmnet defaults to alpha = 1, eg the complete lasso penalty.

* The predict function for glmnet predicts different types of values, including: the predicted class, which predictors are used in the model, and/or the regression paramerter estimates

```{r, cache=TRUE}
glmnetModel <- glmnet(x = as.matrix(training[, fullSet]),
                      y = training$Class,
                      family = "binomial")

# predictions for three different levels of regularization
# note the results are strings not factors
predict(glmnetModel,
        newx = as.matrix(training[1:5, fullSet]),
        s = c(0.05, 0.1, 0.2),
        type = "class")

# which predictors were used in the model?
predict(glmnetModel,
        newx = as.matrix(training[1:5, fullSet]),
        s = c(0.05, 0.1, 0.2),
        type = "nonzero")
```

* As a warning, note that glmnet has a function called auc() (so does pROC). Just be careful which order you load them in. either detach package (eg detach(package:pRoc)) or use namespace convention (eg pROC:::auc) ? I thought it was "::" not ":::"... investigate.

* Can also use train to tune using the area under the ROC curve

```{r, cache=TRUE, warning=FALSE}
glmnGrid <- expand.grid(alpha = c(0, 0.05, 0.1, 0.2, 0.4, 0.6, 0.8, 1),
                        lambda = seq(0.0, 0.2, length = 40))
set.seed(476)
glmnTune <- train(training[, fullSet],
                  y = training$Class,
                  method = "glmnet",
                  tuneGrid = glmnGrid,
                  preProc = c("center", "scale"),
                  metric = "ROC",
                  trControl = ctrl)
```


```{r}
xyplot(ROC ~ lambda,
       data = glmnTune$results,
       groups = alpha,
       type = c("o", "g"),
       auto.key = list(columns = 3,
                       title = "alpha",
                       lines = T,
                       points = F))
```

```{r}
# oh gosh, need to find how to make this non rubbish scale
# might have to pull out stuff and make own heatmap
# rather than custom
trellis.par.set(caretTheme())
glmnPlot <- plot(glmnTune,
                 plotType = "level",
                 cuts = 15,
                 scales = list(x = list(rot = 90, cex = .65)))

update(glmnPlot,
       ylab = "Mixing Percentage\nRidge <---------> Lasso",
       sub = "",
       main = "Area Under the ROC Curve",
       xlab = "Amount of Regularization")
```

## Nearest shrunken Centroids

The initial implementatio is in the pamr package. another package, rda, contains extensions. The implementation in the pamr package is somewhat non standard- needs the predictors to be transposed.

```{r}
inputData <- list(x = t(training[, fullSet]), y = training$Class)
nscModel <- pamr.train(data = inputData)
```

By default the function cooses 30 appropriate shrinkage values to evaluate. There are options to use specified values for teh shrinkage amount, the prior probabilities and other aspects of the model. pamr.predict() genetrates predictions on new samples as well as determines which specific predictors were usied in the model. For example, to specify a shrinkage value of 5

```{r}
exampleData <- t(training[1:5, fullSet])
pamr.predict(nscModel, newx = exampleData, threshold = 5)
```

To determine which predictors were used at the threshold:

```{r}
thresh17Vars <- pamr.predict(nscModel,
                             newx = exampleData,
                             threshold = 17,
                             type = "nonzero"
                             )
fullSet[thresh17Vars]
```

The package also contains function for K-fold CV to chose an appropiate amouunt of shrinkage, but is restrictd to a single type of resampling and tunes the model with overall accuracy. 

Can use train() to give more options for model tuning, as well as a consistent syntax:

```{r, cache=TRUE}
nscGrid <- data.frame(threshold = 0:25)
set.seed(476)
nscTuned <- train(x = training[, fullSet],
                  y = training$Class,
                  method = "pam",
                  preProc = c("center", "scale"),
                  tuneGrid = nscGrid,
                  metric = "ROC",
                  trControl = ctrl)
```

The predict() function for train does not require the user to manually specifit the shrinkage amount. The predictors() function will list the predcitros used in the prediction equation (at optimum threshold)

```{r}
xyplot(ROC ~ threshold,
       data = nscTuned$results,
       type = c("o", "g"))
predictors(nscTuned)
```

Also, can use varImp to return variable importance based on the distance between the class centroid and overall centroid:

```{r}
varImp(nscTuned, scale = FALSE)
```

The positive sign for variable importance implies an increase in event rate, whereas negative implies a decrease in event rate.